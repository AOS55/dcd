algo: ppo
lr: 0.0001
eps: 0.00001
alpha: 0.99
gamma: 0.995
use_gae: True
gae_lambda: 0.95
entropy_coef: 0.0
adv_entropy_coef: 0.0
value_loss_coef: 0.5
max_grad_norm: 0.5
adv_max_grad_norm: 0.5
normalize_returns: False
adv_normalize_returns: False
use_popart: False
adv_use_popart: False
seed: 1
num_processes: 32
num_steps: 256
ppo_epoch: 5
adv_ppo_epoch: 5
num_mini_batch: 1
adv_num_mini_batch: 1
clip_param: 0.2
clip_value_loss: False
clip_reward: None
adv_clip_reward: None
num_env_steps: 500000
reward_shaping: True
use_categorical_adv: True
use_skip: False
choose_start_pos: False
sparse_rewards: False
handle_timelimits: True